{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "# Make sure that caffe is on the python path:\n",
      "#caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
      "import sys\n",
      "import os\n",
      "#print caffe_root\n",
      "#sys.path.insert(0, caffe_root + 'python')\n",
      "sys.path.append('/home/dl/caffe-master/python/')\n",
      "sys.path.append('/usr/lib/python2.7/dist-packages/')\n",
      "\n",
      "import caffe\n",
      "\n",
      "#rootdir = os.getcwd()\n",
      "#print rootdir\n",
      "\n",
      "print 'Done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# iterate all the bits from 16~512\n",
      "from scipy.io import savemat\n",
      "\n",
      "rootdir = '/home/dl/\u6bd5\u4e1a\u8bbe\u8ba1/\u5b9e\u9a8c/cnnh/mnist_hash/'\n",
      "\n",
      "netfile = ['2', '4', '8', '16', '24', '32', '48', '64', '128']\n",
      "\n",
      "# read image data from binary file use numpy.fromstring() and read()\n",
      "rootdata = rootdir + '/dataset/'\n",
      "TEST_DATA_FILE = rootdata + 't10k-images-idx3-ubyte'\n",
      "TEST_LABEL_FILE = rootdata + 't10k-labels-idx1-ubyte'\n",
      "test_num = 10000\n",
      "with open(TEST_DATA_FILE, 'rb') as f:\n",
      "    f.read(16)\n",
      "    test_raw_data = np.fromstring(f.read(test_num * 28*28), dtype = np.uint8)\n",
      "    \n",
      "with open(TEST_LABEL_FILE, 'rb') as f:\n",
      "    f.read(8)\n",
      "    test_labels = np.fromstring(f.read(test_num), dtype = np.uint8)\n",
      "# manually scale data instead of using `caffe.io.Transformer`\n",
      "test_caffe_in = test_raw_data.reshape(test_num, 1, 28, 28) * 0.00390625\n",
      "\n",
      "TRAIN_DATA_FILE = rootdata + 'train-images-idx3-ubyte'\n",
      "TRAIN_LABEL_FILE = rootdata + 'train-labels-idx1-ubyte'\n",
      "train_num = 60000\n",
      "with open(TRAIN_DATA_FILE, 'rb') as f:\n",
      "    f.read(16) # skip the header\n",
      "    train_raw_data = np.fromstring(f.read(train_num * 28*28), dtype=np.uint8)\n",
      "\n",
      "with open(TRAIN_LABEL_FILE, 'rb') as f:\n",
      "    f.read(8) # skip the header\n",
      "    train_labels = np.fromstring(f.read(train_num), dtype=np.uint8)\n",
      "# manually scale data instead of using `caffe.io.Transformer`\n",
      "train_caffe_in = train_raw_data.reshape(train_num, 1, 28, 28) * 0.00390625 \n",
      "\n",
      "\n",
      "\n",
      "roothash = rootdir + '/hash code/'\n",
      "caffe.set_mode_gpu()\n",
      "for i in xrange(9):\n",
      "    print 'processing %s bit hashing' % netfile[i]\n",
      "    rootmodel = rootdir + '/models/mnist ' + netfile[i] + '/'\n",
      "    net = caffe.Net(rootmodel + 'lenet' + '.prototxt', \\\n",
      "                    rootmodel + 'mnist_' + netfile[i] + '_iter_50000.caffemodel', 1)\n",
      "    #net.set_mode_gpu() # use gpu model\n",
      "    test_out = net.forward_all(data=test_caffe_in)\n",
      "    train_out = net.forward_all(data=train_caffe_in)\n",
      "    #hash = np.vstack((test_out.get('hash'+netfile[i]), train_out.get('hash'+netfile[i])))\n",
      "    test_hash = test_out.get('hash')\n",
      "    train_hash = train_out.get('hash')\n",
      "    savemat(roothash+'hash'+netfile[i]+'.mat', {'testh':test_hash, 'trainh':train_hash})\n",
      "\n",
      "#label = np.ndarray((test_num+train_num,), dtype = np.uint8)\n",
      "#label[0:test_num] = test_labels\n",
      "#label[test_num:test_num+train_num] = train_labels\n",
      "savemat(roothash+'label.mat', {'test_label':test_labels, 'train_label':train_labels})\n",
      "\n",
      "print 'Done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing 2 bit hashing\n",
        "processing 4 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 8 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 16 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 24 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 32 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 48 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 64 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 128 bit hashing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use classicication to test the extraction\n",
      "\n",
      "# read image data from binary file use numpy.fromstring() and read()\n",
      "rootdir = '/home/dl/\u6bd5\u4e1a\u8bbe\u8ba1/\u5b9e\u9a8c/cnnh/mnist_hash'\n",
      "rootdata = rootdir + '/dataset/'\n",
      "TEST_DATA_FILE = rootdata + 't10k-images-idx3-ubyte'\n",
      "TEST_LABEL_FILE = rootdata + 't10k-labels-idx1-ubyte'\n",
      "test_num = 10000\n",
      "with open(TEST_DATA_FILE, 'rb') as f:\n",
      "    f.read(16)\n",
      "    test_raw_data = np.fromstring(f.read(test_num * 28*28), dtype = np.uint8)\n",
      "    \n",
      "with open(TEST_LABEL_FILE, 'rb') as f:\n",
      "    f.read(8)\n",
      "    test_labels = np.fromstring(f.read(test_num), dtype = np.uint8)\n",
      "# manually scale data instead of using `caffe.io.Transformer`\n",
      "test_caffe_in = test_raw_data.reshape(test_num, 1, 28, 28) * 0.00390625\n",
      "\n",
      "caffe.set_mode_gpu()\n",
      "net = caffe.Net('/home/dl/\u6bd5\u4e1a\u8bbe\u8ba1/\u5b9e\u9a8c/cnnh/mnist_hash/models/mnist 8/lenet.prototxt', \\\n",
      "                '/home/dl/\u6bd5\u4e1a\u8bbe\u8ba1/\u5b9e\u9a8c/cnnh/mnist_hash/models/mnist 8/mnist_8_iter_50000.caffemodel', \\\n",
      "                1)\n",
      "#net.set_mode_gpu() # use gpu model\n",
      "\n",
      "test_out = net.forward_all(data=test_caffe_in)\n",
      "test_prob = test_out['prob']\n",
      "\n",
      "#print test_caffe_in.shape\n",
      "#print [(k, v.shape) for k, v in test_out.items()]\n",
      "\n",
      "tmp = 0\n",
      "for i in xrange(test_num):\n",
      "    if (test_prob[i].argmax() == test_labels[i]):\n",
      "        tmp = tmp+1\n",
      "print tmp*100.0/test_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99.17\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read image data from binary file use numpy.fromstring() and read()\n",
      "#rootdata = rootdir + '/Zmnist_hash/dataset/'\n",
      "TEST_DATA_FILE = rootdata + 't10k-images-idx3-ubyte'\n",
      "TEST_LABEL_FILE = rootdata + 't10k-labels-idx1-ubyte'\n",
      "test_num = 10000\n",
      "with open(TEST_DATA_FILE, 'rb') as f:\n",
      "    f.read(16)\n",
      "    test_raw_data = np.fromstring(f.read(test_num * 28*28), dtype = np.uint8)\n",
      "    \n",
      "with open(TEST_LABEL_FILE, 'rb') as f:\n",
      "    f.read(8)\n",
      "    test_labels = np.fromstring(f.read(test_num), dtype = np.uint8)\n",
      "# manually scale data instead of using `caffe.io.Transformer`\n",
      "test_caffe_in = test_raw_data.reshape(test_num, 1, 28, 28)\n",
      "print test_caffe_in.shape\n",
      "\n",
      "TRAIN_DATA_FILE = rootdata + 'train-images-idx3-ubyte'\n",
      "TRAIN_LABEL_FILE = rootdata + 'train-labels-idx1-ubyte'\n",
      "train_num = 60000\n",
      "with open(TRAIN_DATA_FILE, 'rb') as f:\n",
      "    f.read(16) # skip the header\n",
      "    train_raw_data = np.fromstring(f.read(train_num * 28*28), dtype=np.uint8)\n",
      "\n",
      "with open(TRAIN_LABEL_FILE, 'rb') as f:\n",
      "    f.read(8) # skip the header\n",
      "    train_labels = np.fromstring(f.read(train_num), dtype=np.uint8)\n",
      "# manually scale data instead of using `caffe.io.Transformer`\n",
      "train_caffe_in = train_raw_data.reshape(train_num, 1, 28, 28)\n",
      "\n",
      "print train_caffe_in.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10000, 1, 28, 28)\n",
        "(60000, 1, 28, 28)\n"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}